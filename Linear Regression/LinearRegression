
#====================
# Regression Analysis
# 회귀분석
#=======================

# 주어진 데이터를 사용해서 변수들 사이의 인과관계를 규명하는 방법 중 가장 대표적인 분석 방법


# 
#
# 수학자 가우스가 1795년 발견
#  
# 데이터는 특정 패턴으로 회귀한다는 패턴에 대한 믿음
# 
# 따라서 "y = w*x + b" 라는 1차 방정식으로 표현 가능하다
# 
# x 는 계수
# 
# S = 변수는 오차의 척도 임. 이 숫자가 크면 오차가 얼마나 많이 발생할 수 있을 지 알수 있음.
#  
# 주의할 점은 LinearRegression(선형회귀)가 인과관계를 알려주지 않는 다는 점이다.
# 예를 들어 커피를 많이 마실 수록 공부 시간이 늘어난다고 결과가 나왔더라도
# 공부시간이 늘어서 커피를 많이 마신건지 아니면 커피를 많이 마셔서 공부시간이 늘어난건지에 대한 대답은 할 수 없다.


# independent variable (독립 변수)
# 종속 변수에 영향을 미치는 요인

# dependaent variable(종속 변수) = explanatory variable(설명 변수) = response variable(반응 변수)
 # 독립변수의 영향에 따라 값이 결정되는 값

# 
# 예측 오차
# 
# 선형회귀를 통해서 추세분석, 역학 조사에서 자주 사용
#
# 통계학의 꽃
#
#
# 두 변수의 상관관계의 크기는 상관계수를 통해서 정량화 됨
# 상관계수로는 Pearson correlation coefficient, Spearman coreeleation coefficient, Kendall correlation coefficient 등이 있음

# R-squared (결정 계수)

# R-squared은 p-value 처럼 Between 0, 1 값으로 나타난다. 
# 해석 방법은 0에 가까울수록 설명력이 낮고 1에 가까울 수록 설명력이 높다고 한다. 


# SSR = Sum of Square Error
# 회귀식과 평균의 차이

# SSE = Sum of Square Regression
# 회귀식과 실재값의 차이

# SST = Sum of Square Total 
# 편차의 제곱

# SST = SSR + SSE

# R^2 = SSR / SSTO

#====
# 실습
#====
data <- as.data.table(state.x77) # 문맹률과 범죄율 선형 관계 보고 예측해보기

head(data)
glimpse(data)

# plot 그리기
ggplot(data, aes(Murder, Illiteracy)) +
  geom_point() +
  geom_smooth(se = FALSE, method = lm)


help("geom_smooth")

names(data.frame(state.x77))

# 단순 선형회귀 모델링
model <- lm(formula = Murder ~ Illiteracy, data)

# 모델링 확인하기
#options(digits = 5) # 자리수 
summary(model)
coef(model)

# 문맹율 0.5 일때 예측
I <- 0.5
Murder = 4.2575 * I + 2.3978
Murder


# 문맹율 1.0 일때 예측
I <- 1.0
Murder = 4.2575 * I + 2.3978
Murder



# Reference
# Hong's Blog
# https://jihongl.github.io/2017/09/16/Rsquared/
# Khan Academy
# https://ko.khanacademy.org/math/statistics-probability/describing-relationships-quantitative-data/assessing-the-fit-in-least-squares-regression/a/r-squared-intuition


