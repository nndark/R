
#====================
# Regression Analysis
# 회귀분석
#=======================

# 주어진 데이터를 사용해서 변수들 사이의 인과관계를 규명하는 방법 중 가장 대표적인 분석 방법


# 
#
# 수학자 가우스가 1795년 발견
#  
# 데이터는 특정 패턴으로 회귀한다는 패턴에 대한 믿음
# 
# 따라서 "y = w*x + b" 라는 1차 방정식으로 표현 가능하다
# 
# x 는 계수
# 
# S = 변수는 오차의 척도 임. 이 숫자가 크면 오차가 얼마나 많이 발생할 수 있을 지 알수 있음.
#  
# 주의할 점은 LinearRegression(선형회귀)가 인과관계를 알려주지 않는 다는 점이다.
# 예를 들어 커피를 많이 마실 수록 공부 시간이 늘어난다고 결과가 나왔더라도
# 공부시간이 늘어서 커피를 많이 마신건지 아니면 커피를 많이 마셔서 공부시간이 늘어난건지에 대한 대답은 할 수 없다.




# 
# 예측 오차
# 
# 선형회귀를 통해서 추세분석, 역학 조사에서 자주 사용
#
# 통계학의 꽃
#
#
# 두 변수의 상관관계의 크기는 상관계수를 통해서 정량화 됨
# 상관계수로는 Pearson correlation coefficient, Spearman coreeleation coefficient, Kendall correlation coefficient 등이 있음

# R-squared (결정 계수)

# R-squared은 p-value 처럼 Between 0, 1 값으로 나타난다. 
# 해석 방법은 0에 가까울수록 설명력이 낮고 1에 가까울 수록 설명력이 높다고 한다. 


# SSR = Sum of Square Error
# 회귀식과 평균의 차이

# SSE = Sum of Square Regression
# 회귀식과 실재값의 차이

# SST = Sum of Square Total 
# 편차의 제곱

# SST = SSR + SSE

# R^2 = SSR / SSTO



# Reference
# Hong's Blog
# https://jihongl.github.io/2017/09/16/Rsquared/
# Khan Academy
# https://ko.khanacademy.org/math/statistics-probability/describing-relationships-quantitative-data/assessing-the-fit-in-least-squares-regression/a/r-squared-intuition


